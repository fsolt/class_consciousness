\documentclass[12pt]{article}
%\usepackage{fullpage}

\usepackage{graphicx}        % Enable graphics commands
\usepackage{lscape}		% Enable landscape with \begin{landscape} until \end{landscape}
\usepackage{natbib}			% Enable citation commands \citep{}, \citet{}, etc.
\bibpunct{(}{)}{;}{a}{}{,}		% Formatting for in-text citations
\usepackage{setspace}		% Enable double-spacing with \begin{spacing}{2} until \end{spacing}.
\usepackage[utf8]{inputenc} 	% Enable utf8 characters, i.e., accents without coding--just type them in.
\usepackage[english]{babel}	% English hyphenation and alphabetization.  Other languages available.
\usepackage{dcolumn}        % For decimal-aligned stargazer/texreg output.
\usepackage[colorlinks=true, urlcolor=blue, citecolor=black, linkcolor=black]{hyperref} % Include hyperlinks with the \url and \href commands.
\setlength{\tabcolsep}{1pt}	% Make tables slightly narrower by reducing space between columns.
\usepackage{afterpage}
\usepackage{hanging}
\usepackage[margin=1in]{geometry}

\usepackage{ntheorem}
\newtheorem{hyp}{Hypothesis} 

\renewcommand\floatpagefraction{.9}	% These commands allow larger tables and graphics to fit
\renewcommand\topfraction{.9}		% on a page when default settings would complain.
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\newcommand{\R}{\textsf{R}~}        %This creates the command \R to typeset the name R correctly.
\mathchardef\mhyphen="2D            %Math-mode hyphen

%\usepackage[left=1in, right=1in]{geometry}	
%Turn footnotes into endnotes (commented out).
%\renewcommand{\footnotesize}{\normalsize}	
% \usepackage{endnotes}
% \renewcommand{\footnote}{\endnote}
\renewcommand{\section}{\subsubsection}

\begin{document}

<<label=preamble, include=FALSE>>=
if (!require(pacman)) install.packages("pacman")
library(pacman)
p_load(knitr)
opts_chunk$set(concordance=TRUE, cache=TRUE, warning=FALSE, message=FALSE, echo=FALSE, results='hide')
@

\title{Economic Inequality and\\ Class Consciousness in the United States\thanks{Revision history and the materials needed to reproduce the analyses of this paper can be found \href{https://github.com/fsolt/class_consciousness}{on Github here}.}}
\author{
  Frederick Solt\\
  \href{mailto:frederick-solt@uiowa.edu}{frederick-solt@uiowa.edu}
  \and
  Yue Hu\\
  \href{mailto:yue-hu-1@uiowa.edu}{yue-hu-1@uiowa.edu}
    \and
	Kevan Hudson\\
	\href{mailto:kevan-hudson@uiowa.edu}{kevan-hudson@uiowa.edu}
	\and
	Jungmin Song\\
    \href{mailto:jungmin-song@uiowa.edu}{jungmin-song@uiowa.edu}
	\and
	Dong `Erico' Yu\\
    \href{mailto:dong-yu@uiowa.edu}{dong-yu@uiowa.edu}
}
\date{\today}				
\maketitle

\begin{spacing}{2}
\begin{abstract}

\end{abstract}

\newpage
One of the most important questions underlying recent research on economic inequality and democracy is whether inequality in democratic contexts is self-correcting or instead self-reinforcing.  
Rational choice arguments have long maintained that, where economic inequality is higher, the benefit of more redistributive policies to the median voter and to those with below-median incomes will be greater, leading them to demand and achieve the adoption of higher taxes and more government spending to ameliorate unequal conditions between those with higher and lower incomes \cite[see, e.g.,][]{Meltzer1981}.

[unequal democracy / relative power stuff]

A prominent recent study, \citet[hereafter NJL]{Newman2015}, argues in favor of the former, more optimistic view.  
It contends that simply being exposed to high levels of local income inequality prompts those with lower incomes to become more likely to view the United States as divided into haves and have-nots and to see themselves as among the have-nots, that is, to become more likely to achieve a class consciousness vital to contesting the fairness of the economic system and mobilizing in favor of redistribution. 
%Unfortunately, the article's own reported results do not support this conclusion, and its analysis suffers from additional issues that render even those results untrustworthy.
%Our independent replication using more and better data, in fact, yields the opposite result: lower-income people living where local levels of income inequality are higher are less likely to reject meritocracy than those living where the income distribution is more egalitarian.

<<label=setup>>==
p_load(readr, haven, ggplot2, magrittr, stringr, lme4, mi, betareg, truncnorm, mitools, beepr, pewdata, dplyr)
p_load_gh("fsolt/dotwhisker") # until CRAN updated with new by_2sd
@


<<label=format_fxns>>==
gen_partyid <- function(df) {
	pid <- rep(NA, length(df$party))
	pid[df$party==1 & df$partystr==1] <- 5
	pid[df$party==1 & df$partystr==2] <- 4
	pid[df$partyln==1] <- 4
	pid[(df$party==3 | df$party==4) & df$partyln==9] <- 3
	pid[df$partyln==2] <- 2
	pid[df$party==2 & df$partystr==2] <- 2
	pid[df$party==2 & df$partystr==1] <- 1
	return(pid)
}

gen_partyid2 <- function(df) {
	pid <- rep(NA, length(df$party))
	pid[df$party==1 & df$partystr==1] <- 7
	pid[df$party==1 & df$partystr==2] <- 6
	pid[df$partyln==1] <- 5
	pid[(df$party==3 | df$party==4) & df$partyln==9] <- 4
	pid[df$partyln==2] <- 3
	pid[df$party==2 & df$partystr==2] <- 2
	pid[df$party==2 & df$partystr==1] <- 1
	return(pid)
}

hhn_format <- function(df, cfips, dh, hn) {
	# clean a Pew have/have-not survey dataset and merge it with county-level data
	# df: data; cfips: var of county fips; dh: var of U.S. divided; hn: var of self-id as have-not
    surv <- str_replace(deparse(substitute(df)), "hhn", "20")
    all_vars <- c("income", "educ", "age", "sex", "racethn", "race", "hisp", 
                  "labor", "ideo", "attend", "employ",
    			  "party", "partystr", "partyln")
    vars <- c(cfips, dh, hn, all_vars[all_vars %in% names(df)])
    df %<>% select(one_of(vars))
    names(df)[1:3] <- c("cfips", "dh", "hn")
    df %<>% mutate(
        fips = as.integer(cfips),
        state = floor(fips/1000),
        div_hhn = ifelse(dh==1, 1, ifelse(dh==2, 0, NA)),
        have_not = ifelse(hn==2, 1, ifelse(hn==1, 0, NA)),
        income = as.integer(ifelse(income<=9, income, NA)), # 1 to 9
        educ = as.integer(ifelse(educ<=7, educ, NA)), # 1 to 7
        age = ifelse(age<99, age, NA),
        male = ifelse(sex==1, 1, 0),
        ideo = as.integer(6 - ifelse(ideo<=5, ideo, NA)) # 1 to 5
    )
    df$partyid <- gen_partyid(df)
    if (names(df) %>% str_detect("racethn") %>% any()) {
        df %<>% mutate(white = ifelse(racethn==1, 1, 0))
    } else df %<>% mutate(white = ifelse(race==1 & hisp!=1, 1, 0))
    if (names(df) %>% str_detect("labor") %>% any()) {
        df %<>% mutate(union = ifelse(labor<=3, 1, ifelse(labor==4, 0, NA)))
    } else df %<>% mutate(union = NA)
    if (names(df) %>% str_detect("attend") %>% any()) {
        df %<>% mutate(attend = 7 - ifelse(attend<=6, attend, NA))
    } else df %<>% mutate(attend = NA)
    if (names(df) %>% str_detect("employ") %>% any()) {
        df %<>% mutate(emp = ifelse(employ<3, 1, ifelse(employ==3, 0, NA)))
    } else df %<>% mutate(emp = NA)

    df$survey <- surv
    
    vars2 <- c("fips", "state", "div_hhn", "have_not", "income", "educ", "age", "male", "white", 
               "union", "emp", "partyid", "ideo", "attend", "survey")
    df %<>% select(one_of(vars2)) %>% left_join(cnty_data, by = "fips") %>% filter(white==1)
} 

hhn_mi <- function(df, seed=324) {
	# multiply impute missing data in a cleaned and merged Pew dataset
    mdf <- missing_data.frame(as.data.frame(df))
    mdf <- change(mdf, y = c("fips", "state"), what = "type", to = "irrelevant")
    mdf <- change(mdf, y = c("income", "educ", "attend"), what = "type", to = "ordered-categorical")
    mdf <- change(mdf, y = "age", what = "type", to = "bounded-continuous", lower=18, upper=97)
    mdf_mi <- mi(mdf, seed=seed) 
    
    # switch to mitools format (no support for glmer in mi::pool)
    mdf_mi_list <- complete(mdf_mi, m=10) 
    mdf_mi_list <- lapply(mdf_mi_list, function(df) 
        sapply(df, function(v) 
            if(any(class(v)=="factor")) v <- as.numeric(levels(v))[v] else v <- v) %>% data.frame) # get rid of %&*(&^ factors
    imputationList(mdf_mi_list)
}

format_mi_results <- function(m) {
	# format results of analysis of multiply imputed Pew dataset
    m_fe <- MIextract(m, fun=fixef) # see https://books.google.com/books?id=EbLrQrBGid8C&pg=PA384
    m_vars <- MIextract(m, fun=vcov)
    m_vars2 <- list()
    m_vars2 <- lapply(m_vars, as.matrix)
    m_res <- MIcombine(m_fe, m_vars2)
    b <- m_res$coefficients
    se <- diag(m_res$variance^.5)
    df <- data.frame(term = names(b),
               estimate = b,
               std.error = se,
               model = deparse(substitute(m)), 
               stringsAsFactors = FALSE)
    df %>% filter(term!="(Intercept)")
}
@

<<label=county_data>>==
## Replicate county-level data from sources
fips_cnty <- read_csv("https://raw.githubusercontent.com/raypereda/fips-county-codes/master/lib/national.txt", 
					  col_types="ccccc") 
names(fips_cnty) <- tolower(gsub(" ", "_", names(fips_cnty)))
fips_cnty$fips <- as.numeric(do.call(paste0, c(fips_cnty[, c(2,3)])))
fips_cnty$county <- tolower(gsub(" County| Parish", "", fips_cnty$county_name))
fips_cnty$county <- gsub(" ", "", fips_cnty$county)

bush04 <- read_tsv("http://bactra.org/election/vote-counts-with-NE-aggregated")
bush04$perc_bush04 <- with(bush04, Bush/(Bush+Kerry+Nader))
names(bush04) <- tolower(names(bush04))
bush04$county <- tolower(gsub(" County| Parish", "", bush04$county))
bush04$county <- gsub("saint", "st.", bush04$county)
bush04$county <- gsub(" ", "", bush04$county)
bush04$county[(bush04$state=="LA"|bush04$state=="MS") & bush04$county=="jeffdavis"] <- "jeffersondavis"
bush04$county[(bush04$state=="ME") & bush04$county=="linc"] <- "lincoln"
bush04$county[(bush04$state=="ME") & bush04$county=="andr"] <- "androscoggin"
bush04$county[(bush04$state=="ME") & bush04$county=="pen-s"] <- "penobscot"
bush04$county[(bush04$state=="ME") & bush04$county=="som-s"] <- "somerset"
bush04$county[(bush04$state=="ME") & bush04$county=="oxf-s"] <- "oxford"
bush04$county[(bush04$state=="MA") & bush04$county=="hamd"] <- "hamden"
bush04$county[(bush04$state=="MA") & bush04$county=="esse"] <- "essex"
bush04$county[(bush04$state=="MA") & bush04$county=="hams"] <- "hampshire"
bush04$county[(bush04$state=="NH") & bush04$county=="graf"] <- "grafton"
bush04$county[(bush04$state=="NY") & bush04$county=="manhattan"] <- "newyork"
bush04$county[(bush04$state=="NY") & bush04$county=="statenisland"] <- "richmond"
bush04$county[(bush04$state=="NY") & bush04$county=="brooklyn"] <- "kings"
bush04$county[(bush04$state=="VT") & bush04$county=="fran"] <- "franklin"
bush04$county[(bush04$state=="VT") & bush04$county=="wins"] <- "windsor"
bush04$county[(bush04$state=="VT") & bush04$county=="addi"] <- "addison"
bush04$county[(bush04$state=="VT") & bush04$county=="gris"] <- "grandisle"
bush04$county[(bush04$state=="VT") & bush04$county=="oran"] <- "orange"
bush04$county[(bush04$state=="VA") & bush04$county=="manassas"] <- "manassascity"
bush04$county[(bush04$state=="VA") & bush04$county=="norton"] <- "nortoncity"

bush04_cnty <- left_join(bush04, fips_cnty)
missing <- bush04_cnty[is.na(bush04_cnty$fips), 1:8] # election results still without fips due to county name inconsistencies
bush04_cnty <- bush04_cnty[!is.na(bush04_cnty$fips), ] # keep only results that already have fips
remaining <- anti_join(fips_cnty, bush04) %>% arrange(state) # fips without election results

missing$county0 <- missing$county # move county names to a tempvar
missing$county <- NA

states <- unique(missing$state)
states <- states[states != "AK"] # nothing to be done with Alaska election results--no breakdown in data
for(i in 1:length(states)) {
	t.rem <- remaining$county[remaining$state==states[i]] # fips without election results, one state at a time
	missing$county[missing$state==states[i]] <- lapply(missing$county0[missing$state==states[i]], function (ii) agrep(ii, t.rem, value=T, max.distance=.2)) # find matches to county name by state
}
missing$county <- unlist(lapply(missing$county, function(ii) ii[1])) # use closest match to county name
missing <- left_join(missing, fips_cnty) # now merge; some results still without fips in Maine, otherwise good
missing$county0 <- NULL # drop tempvar

bush04_cnty %<>% rbind(missing) %>% select(fips, perc_bush04)

acs0509 <- read_csv("../data/acs0509-counties.csv") # this throws warnings; they are irrelevant
names(acs0509) <- tolower(names(acs0509))
acs0509 <- mutate(acs0509,
				  fips = as.numeric(gsub("05000US", "", geoid)),
				  gini_cnty = b19083_001e,
				  income_cnty = b19013_001e/10000,
				  black_cnty = b02001_003e/b02001_001e,
				  pop_cnty = b02001_001e/10000)
cnty_data <- select(acs0509, fips:pop_cnty) %>% left_join(bush04_cnty)
@

<<label=pew_data>>==
# Save contact info to .Rprofile before running this document:
#  options("pew_name" = "Juanita Herrera",
#         "pew_org" = "Upper Midwest University",
#         "pew_phone" = "888-000-0000",
#         "pew_email" = "jherrera@uppermidwest.edu")
# You must also have Firefox (available at <firefox.com>) installed on your machine

if (!file.exists("../data/pew/haves_havenots/Values09/Values09c.sav")) {
pew_download(file_id = c(20018505, #Oct05NII
                         20018544, #Sept06
                         20018407, #July07
                         20018374, #Jan08
                         20018335, #EarlyOct08
                         20018560  #Values09
                         ), download_dir = "../data/pew/haves_havenots/")  
}


@

<<label=t2_reproduction>>==
vars_list <- c("gini_cnty", "income_cnty", "black_cnty", "perc_bush04", "pop_cnty", "income",
              "educ", "age", "male", "union", "emp", "partyid", "ideo", "attend", "(Intercept)")
vars_proper <- c("Income Inequality", "Median Household Income", "Percent Black", 
                 "Bush Vote", "Total Population", 
                 "Income", "Education", "Age", "Male", "Union Membership",
                 "Employed", "Republican Party ID", "Conservative Ideology",
                 "Religious Attendance")

### 2006 (Table 2)
hhn06 <- read_dta("../data/pew/haves_havenots/Sept06/Sept06NIIc.dta") # Converted first with StatTransfer as read_sav didn't work
hhn06x <- hhn_format(hhn06, cfips="fips", dh="q52", hn="q53")

hhn06x_mi <- hhn_mi(hhn06x) # multiply impute missing data

t2 <- with(hhn06x_mi, 
              glmer(formula = div_hhn~gini_cnty+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        income+educ+age+male+union+emp+partyid+ideo+attend+
                        (1|fips), family=binomial(link="logit")))
t2_res <- format_mi_results(t2)
#dwplot(t2_res)
@

<<label=t2_replication_all>>==
### additional data
# load all datasets
hhn05 <- read_sav("../data/pew/haves_havenots/Oct05NII/Oct05NIIc.sav") # Oct05NII (all controls)
hhn06 <- read_dta("../data/pew/haves_havenots/Sept06/Sept06NIIc.dta") # used in Table 2
hhn07 <- read_sav("../data/pew/haves_havenots/July07/July07c.sav") # July07 (missing labor, employ)
hhn0801 <- read_dta("../data/pew/haves_havenots/Jan08/Jan08c.dta") # Jan08 (all controls)
hhn0810 <- read_sav("../data/pew/haves_havenots/EarlyOct08/EarlyOct08c.sav") # EarlyOct2008 (missing labor, attend)
hhn09 <- read_sav("../data/pew/haves_havenots/Values09/Values09c.sav") %>% # Values09 (all controls, but only Survey B asked hhn)
    filter(values==2) # keep only Survey B, which asked hhn questions

# no fips in Apr10-political-future;
#               Sept 22-25 2011 omnibus public; or 
#               Dec11 Political (they're too late for the acs0509 contextual data anyway)

# format all datasets
hhn05x <- hhn_format(hhn05, cfips="qfips", dh="q52", hn="q53")
hhn06x <- hhn_format(hhn06, cfips="fips", dh="q52", hn="q53")
hhn07x <- hhn_format(hhn07, cfips="qfips", dh="q40", hn="q41")
hhn0801x <- hhn_format(hhn0801, cfips="fips", dh="q33", hn="q34")
hhn0810x <- hhn_format(hhn0810, cfips="zfips", dh="q56", hn="q57")
hhn09x <- hhn_format(hhn09, cfips="fips", dh="qb28", hn="qb29")

# combine data
hhn <- rbind(hhn05x, hhn06x, hhn07x, hhn0801x, hhn0810x, hhn09x)
rm(list = ls(pattern="hhn0[5789].*")) # free up memory

hhn_mi <- hhn_mi(hhn)

t2_all <- with(hhn_mi, 
              glmer(formula = div_hhn~gini_cnty+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        income+educ+age+male+union+emp+partyid+ideo+attend+
                        (1|fips), family=binomial(link="logit")))
t2_all_res <- format_mi_results(t2_all)
@

<<label=t2_rep_all_plot>>==
level_brackets <- list(c("County-Level", "gini_cnty", "pop_cnty"),
                       c("Individual-Level", "income", "attend"))

p <- t2_res %>% by_2sd(hhn06x) %>%
    rbind(t2_all_res %>% by_2sd(hhn)) %>% dwplot +
    relabel_y_axis(vars_proper) +
    theme_bw() + xlab("Coefficient Estimate") +
    geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
    theme(legend.justification=c(0, 1), legend.position=c(0, 1),
          legend.background = element_rect(colour="grey80"),
          legend.title.align = .5,
          legend.text = element_text(size = 9),
          legend.key.height = unit(12, "pt")) +
    scale_colour_grey(start = .7, end = .5,
                      name = "Data",
                      breaks = c("t2", "t2_all"),
                      labels = c("Pew 2006", "Pew 2005-2009"))
g <- p %>% add_brackets(level_brackets)
ggsave("figures/t2_pooled.pdf", plot = g, width = 6, height = 5)  
@

<<label=t2_replication_each>>==
# Does any other single dataset yield same result as 2006? no
yrs <- c(2005, 2007, 200801, 200810, 2009)

for (i in 1:length(yrs)) {
    ds <- lapply(hhn_mi$imputations, function(x) x[x$survey==yrs[i],, drop=F]) %>% imputationList()
    res <- with(ds, 
              glmer(formula = div_hhn~gini_cnty+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        income+educ+age+male+union+emp+partyid+ideo+attend+
                        (1|fips), family=binomial(link="logit")))
    tidy_res <- format_mi_results(res)
    tidy_res$model <- paste("Pew", yrs[i])
    if (i==1) t2_by_survey <- tidy_res else t2_by_survey <- rbind(t2_by_survey, tidy_res)
}
@

<<label=t2_rep_each_plot>>==
t2_by_survey %<>% rbind(t2_res %>% mutate(model = "Pew 2006")) %>% 
	arrange(model) # use 2006 data mi'd separately for consistency w first plot

sw <- secret_weapon(t2_by_survey, "gini_cnty") +
  theme_bw() + xlab("Coefficient Estimate, County Gini Index") + ylab("") + 
  relabel_y_axis(c("Oct 2005", "Sept 2006", "July 2007", 
                   "Jan 2008", "Oct 2008", "Apr 2009")) +
  geom_vline(xintercept = 0, colour = "grey60", linetype = 2) + 
  theme(legend.position = "none") +
  scale_colour_grey(start = .5)
ggsave("figures/t2_by_survey.pdf", plot = sw, width = 6, height = 3)
@


<<label=t3_replication>>==
vars_list_t3 <- c("gini_cnty", "income", "gini_cnty:income", "income_cnty",
                  "black_cnty", "perc_bush04", "pop_cnty",
                  "educ", "age", "male", "union", "emp", "partyid", "ideo", "attend")
t3_all <- with(hhn_mi, 
              glmer(formula = have_not~gini_cnty+income+gini_cnty:income+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        educ+age+male+union+emp+partyid+ideo+attend+
                        (1+income|fips), family=binomial(link="logit")))
t3_all_res <- format_mi_results(t3_all)
t3_all_res <- t3_all_res[match(vars_list_t3, t3_all_res$term),]
@

<<label=t3_plot>>==
# Table 3 isn't reproducible as presented: it has more parameters than observations
# so we have to enter the reported results by hand
t3_data <- read_tsv("../data/study_26584/Meritocracy Replication Data - Table 3.tab")
t3_rep <- data_frame(term = c("ginicnty", "income_i", "ginicnty:income_i", "income_cnty",
                              "black_cnty", "perc_bush04", "pop_cnty", 
                              "educ_i", "age_i", "gender_i", "union_i",
                              "unemp_i", "partyid_i", "ideo_i", "attend_i"),
               estimate = c(2.27, -1.76, -4.59, .625, -.082, 1.95, 
                            1.09, -.679, -.008, .156, .274,
                            .358, -1.49, -.538, -.058),
               std.error = c(1.50, 1.05, 2.62, .677, .632, .661,
                             .835, .361, .006, .170, .235,
                             .205, .274, .401, .273),
               model = "t3") %>% 
  by_2sd(t3_data)
t3_rep$term = t3_all_res$term

level_brackets <- list(c("County-Level Controls", "income_cnty", "pop_cnty"),
                       c("Individual-Level Controls", "educ", "attend"))

vars_proper_t3 <- c("Income Inequality", "Income", "Inequality x Income",
                    "Median Household Income", "Percent Black", "Bush Vote",
                    "Total Population", "Education", "Age", "Male", 
                    "Union Membership", "Employed", "Republican Party ID", 
                    "Conservative Ideology", "Religious Attendance")

p3 <- t3_rep %>%
  rbind(t3_all_res %>% by_2sd(hhn)) %>% 
  dwplot(alpha = .1) +
    relabel_y_axis(vars_proper_t3) +
    theme_bw() + xlab("Coefficient Estimate") +
    geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
    theme(legend.justification=c(0, 0), legend.position=c(0, 0),
          legend.background = element_rect(colour="grey80"),
          legend.title.align = .5,
          legend.text = element_text(size = 9),
          legend.key.height = unit(12, "pt")) +
    scale_colour_grey(start = .7, end = .5,
                      name = "Data",
                      breaks = c("t3", "t3_all"),
                      labels = c("Pew 2006, Reported", "Pew 2005-2009")) 

g3 <- p3 %>% add_brackets(level_brackets)
ggsave("figures/t3_pooled.pdf", plot = g3, width = 6, height = 5)
@

<<label=t3_inter_gini>>==
p_load(interplot)
inc_labels <- c("<$10k", "$10-20k", "$20-30k", "$30-40k", "$40-50k",
                "$50-75k", "$75-100k", "$100-150k", ">$150k")
t3_inter_gini <- interplot(t3_all, "gini_cnty", "income") +
  scale_x_continuous(breaks = seq(length(inc_labels)), labels = inc_labels) + 
  coord_cartesian(ylim = c(-10, 5)) +
  labs(x = "Income", 
       y = "Coefficient of Inequality on Identifying as a 'Have-Not'") +
  theme_bw() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=8),
        axis.title.y = element_text(size=8)) +
  geom_hline(yintercept = 0, colour = "grey80", linetype = "dashed") +
  scale_colour_grey(start = .5)

ggsave(filename="figures/t3_inter_gini.pdf", plot = t3_inter_gini, width = 7, height = 7)

save(t3_inter_gini, file = 'cache/t3_inter_gini.RData') # naive cache, per https://groups.google.com/forum/#!topic/knitr/3mPn2neMdrk, to cope with lazyLoad() bug
rm(t3_inter_gini) 
@

<<label=t3_inter_inc>>==
t3_inter_inc <- interplot(t3_all, "income", "gini_cnty") +
  coord_cartesian(xlim = c(0.3, 0.6)) +
  labs(x = "Income Inequality", 
       y = "Coefficient of Income on Identifying as a 'Have-Not'") +
  theme_bw() +
  theme(axis.title.y = element_text(size=8))

ggsave(filename="figures/t3_inter_inc.pdf", plot = t3_inter_inc, width = 7, height = 7)

save(t3_inter_inc, file = 'cache/t3_inter_inc.RData') # naive cache to cope with lazyLoad() bug
rm(t3_inter_inc) 
@

<<label=t3_predprob>>==
pred_probs <- function(m, var1, var2, var2_vals,
                       times = 20, sims = 1000) {
  m_list <- m
  m <- m_list[[1]]
  class(m_list) <- class(m)
  m_sims_list <- lapply(m_list, function(i) arm::sim(i, sims))
  m_sims <- m_sims_list[[1]]
  
  for (i in 2:length(m_sims_list)) {
    m_sims@fixef <- rbind(m_sims@fixef, m_sims_list[[i]]@fixef)
    m_sims@ranef[[1]] <- abind::abind(m_sims@ranef[[1]], m_sims_list[[i]]@ranef[[1]], along = 1)
  }
  
  df <- data.frame(m@frame)
  df[[names(m@flist)]] <- NULL # omit L2 var
  names(df)[1] <- "(Intercept)" # replace DV with intercept
  df$`(Intercept)` <- 1
  
  # Find name of interaction term
  ifelse(var1 == var2, var12 <- paste0("I(", var1, "^2)"), 
         var12 <- paste0(var2, ":", var1))
  if (!var12 %in% unlist(dimnames(m@pp$X)[2])) 
    var12 <- paste0(var1, ":", var2)
  if (!var12 %in% unlist(dimnames(m@pp$X)[2])) 
    stop(paste("Model does not include the interaction of", var1, "and", 
               var2, "."))
  
  iv_medians <- summarize_each(df, funs(median(., na.rm = TRUE))) 

  fake_data <- iv_medians[rep(1:nrow(iv_medians), each=times*length(var2_vals)), ] 
  fake_data[[var1]] <- with(df, rep(seq(min(get(var1)), max(get(var1)), length.out=times),
                                    times=length(var2_vals)))
  fake_data[[var2]] <- rep(var2_vals, each=times)
  fake_data[[var12]] <- fake_data[[var1]] * fake_data[[var2]]

  pp <- rowMeans(plogis(data.matrix(fake_data) %*% t(data.matrix(m_sims@fixef))))
  row_quantiles <- function (x, probs) {
    naValue <- NA
    storage.mode(naValue) <- storage.mode(x)
    nrow <- nrow(x)
    q <- matrix(naValue, nrow = nrow, ncol = length(probs))
    if (nrow > 0L) {
      t <- quantile(x[1L, ], probs = probs)
      colnames(q) <- names(t)
      q[1L, ] <- t
      if (nrow >= 2L) {
        for (rr in 2:nrow) {
          q[rr, ] <- quantile(x[rr, ], probs = probs)
        }
      }
    }
    else {
      t <- quantile(0, probs = probs)
      colnames(q) <- names(t)
    }
    q <- drop(q)
    q
  }
  pp_bounds <- row_quantiles(plogis(data.matrix(fake_data) %*% t(data.matrix(m_sims@fixef))), prob = c(.025, .975))
  pp <- cbind(pp, pp_bounds)
  pp <- pp*100
  colnames(pp) <- c("est", "lb", "ub")
  pp <- cbind(fake_data, pp)
  pp$income <- as.factor(pp$income)
  return(pp)
}

t3_pp <- pred_probs(t3_all, var1 = "gini_cnty", var2 = "income", 
                    var2_vals = c(1, 5, 9), times = 50, sims = 1000)

t3_pp_plot <- ggplot(t3_pp, aes(x = gini_cnty, y = est, group = income)) + 
  geom_line(aes(colour = income)) + 
  geom_ribbon(aes(ymin=lb, ymax=ub, fill = income), alpha=.45) +
  coord_cartesian(xlim = c(0.3, 0.6)) +
  xlab("Income Inequality") + 
  ylab("Predicted Probability of Identifying as a 'Have-Not'") +
  theme_bw() + theme(legend.position="none",
        axis.title.y = element_text(size=8)) +
  theme(plot.title = element_text(face="bold")) +
  geom_text(aes(.40, 79.5, label="<$10k", color="1")) +
  geom_text(aes(.46, 44, label="$40-50k", color="5")) +
  geom_text(aes(.52, 2, label=">$150k", color="9")) +
  scale_colour_manual(values = c("grey60", "grey40", "grey5")) +
  scale_fill_manual(values = c("grey60", "grey40", "grey5"))
ggsave("figures/t3_pp_plot.pdf", plot = t3_pp_plot, width = 7, height = 7)
@

<<label=t3_multi, cache=FALSE>>==
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
    require(grid)
    
    # Make a list from the ... arguments and plotlist
    plots <- c(list(...), plotlist)
    
    numPlots = length(plots)
    
    # If layout is NULL, then use 'cols' to determine layout
    if (is.null(layout)) {
        # Make the panel
        # ncol: Number of columns of plots
        # nrow: Number of rows needed, calculated from # of cols
        layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                         ncol = cols, nrow = ceiling(numPlots/cols))
    }
    
    if (numPlots==1) {
        print(plots[[1]])
        
    } else {
        # Set up the page
        grid.newpage()
        pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
        
        # Make each plot, in the correct location
        for (i in 1:numPlots) {
            # Get the i,j matrix positions of the regions that contain this subplot
            matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
            
            print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                            layout.pos.col = matchidx$col))
        }
    }
}

load("cache/t3_inter_inc.RData") # naive cache for lazyLoad() bug
load("cache/t3_inter_gini.RData") # naive cache for lazyLoad() bug

pdf(file="figures/t3_multi.pdf", width=8, height=3.5)
multiplot(t3_inter_inc, t3_inter_gini, t3_pp_plot, layout = matrix(c(1, 2, 3), nrow=1))
graphics.off()

rm(t3_inter_inc, t3_inter_gini) # discard naively cached objects
@



An important step in the process of conducting sound research is striving to utilize all available data. 
Researchers should seek to conduct their analysis on the entirety of data that they have at their disposal. 
Doing so provides a number of benefits:  it increases the likelihood that the sample utilized captures the true distribution of the underlying population, and it affords greater leverage in testing the implications of one’s hypothesis. 
While the issue of selection bias cannot be avoided simply by including all available data, limiting analysis to a particular dataset, particularly when alternatives are available, may cast doubt on the inferences drawn from that analysis. 
By including all relevant data researchers are better able to observe the implications of their theory, thus providing greater support for the hypotheses they advance.

%If research is limited to a particular source of data, the findings may be called into question. The limited data may provide evidence of a relationship that is not present in a larger, more representative sample. We can draw an example of the dangers of not including all relevant data from \citet{Newman2015}.  In an attempt to test some underlying assumptions of their theory the authors rely on 2006 Pew Research Center dataset due to its 
NJL claims to employ ``an additional national data set conducted by the Pew Research Center in 2006 containing a unique set of questions tapping perceptions of economic hierarchy and inequality and respondents perception of their own position within such a hierarchy'' \citep[336]{Newman2015}. 
%As presented by the authors, this dataset provides the only source of information on responses to the question whether or not an American thinks of America as being divided into haves and have-nots, and whether they think of themselves as being haves or have-nots. Employing this dataset the authors find further support for their theory, in situations of higher inequality respondents are more likely to believe that America is divided in such a way, and the poor are more likely to identify themselves as have-nots. 
In reality, these questions are not unique to the 2006 dataset, but are instead present in a number of Pew surveys, including some used in the paper's earlier analysis. 
Perhaps it is by coincidence that, as shown in Figure \ref{F:t2_by_survey}, the coefficient of interest only achieves statistical significance when using the 2006 data. 
As illustrated, no other dataset produces a statistically significant coefficient for Gini according to the authors’ model. 
This provides a clear illustration of the importance of including all relevant data; failure to do so can lead to biased results.

\begin{figure}[htbp] 
  \caption{Local Inequality and the Perception of America as Divided into `Haves' and `Have-Nots': Results Using All Available Data}
  \label{F:t2_pooled}
  \begin{center}
    \includegraphics[width=5.25in]{figures/t2_pooled.pdf}
  \end{center}
  \begin{footnotesize}
  \begin{tabular}{p{.1in} p{6.1in}}
  & \emph{Notes}: Dots indicate estimates; whiskers represent 95\% confidence intervals. 
Results from replications of the model presented in Table 2 of \citet{Newman2015} on the 2006 Pew survey analyzed in that article and on pooled data from the six Pew surveys that included the same item and were conducted in the time period the article examines.
The statistically significant result for county income inequality in the 2006 survey presented in that article is not evident when all of the available data are examined.
  \end{tabular}
  \end{footnotesize}
\end{figure}

The authors’ use of this severely truncated data has implications beyond the coefficient of interest as well. 
While Figure~\ref{F:t2_pooled} clearly demonstrates that a more careful inclusion of all data produce results that run counter to the findings of Newman et al, including all available data drastically changes the entre model, not merely the coefficient for Gini. 
Figure~\ref{F:t2_pooled} provides estimates of the coefficients from Newman et al’s Table 2 (p. 336) with a sample that includes data from the 2005, 2006, 2007, and 2009 surveys they use earlier in their article. 
When all relevant data is included, the results are drastically different. 
Not only does the primary variable of interest (Gini coefficient) lose statistical significance, but others do as well. 
Having voted for Bush is no longer a statistically significant predictor of believing America is divided into the haves and have-nots, but income becomes strongly negative and significantly associated with the same belief. 
Additionally, union membership gains statistical significance, indicating that belonging to a union increases the likelihood an individual perceives that have/have-not division. 
Ultimately, Figure~\ref{F:t2_pooled} provides graphical representation of the dangers of not including all available data. 
By limiting their analysis to the sole dataset that produced a statistically significant coefficient for inequality, the authors have disguised the true relationship in order to support their theory. 
A properly crafted analysis reveals findings that are far less surprising; the wealthy are less likely to see America as divided into the haves and have-nots, while union members are more likely to do so. 
These findings counter the primary argument advanced by NJL, and lend strong evidence to the claim that ``we should be willing to take whatever information we can acquire so long as it helps us learn about the veracity of our theory,'' while illustrating the pitfall of picking and choosing data that confirm our theory, while ignoring data that does not \citep[31]{King1994}.




\begin{figure}[htbp] 
  \caption{Local Inequality and the Perception of America as Divided into `Haves' and `Have-Nots': Results Using Each Available Dataset}
  \label{F:t2_by_survey}
  \begin{center}
    \includegraphics[width=5.25in]{figures/t2_by_survey.pdf}
  \end{center}
  \begin{footnotesize}
  \begin{tabular}{p{.1in} p{6.1in}}
  & \emph{Notes}: Dots indicate estimates; whiskers represent 95\% confidence intervals.  
Results for county income inequality from replications of the model presented in NJL Table 2 on data from each of six available surveys conducted in the in the time period examined in that article.  
Of the six surveys, the only one that yields a statistically significant result is the 2006 survey presented in the article.
  \end{tabular}
  \end{footnotesize}
\end{figure}

%%%% Jungmin here

practice

\begin{figure}[htbp] 
  \caption{Local Inequality and Self-Identification as a `Have-Not': Results Using All Available Data}
  \label{F:t3_pooled}
  \begin{center}
    \includegraphics[width=5.25in]{figures/t3_pooled.pdf}
  \end{center}
  \begin{footnotesize}
  \begin{tabular}{p{.1in} p{6.1in}}
  & \emph{Notes}: Dots indicate estimates; whiskers represent 90\% confidence intervals.
Results obtained by replicating the analysis from NJL Table 3 on pooled data from the six Pew surveys that included the same item conducted in the time period examined in that article.
The published NJL analysis, purportedly of the 2006 Pew survey, is not reproducible because it includes more parameters than observations; the reported results are depicted here.  
  \end{tabular}
  \end{footnotesize}
\end{figure}

%%%% HU here

\begin{figure}[htbp] 
  \caption{Conditional Effects of Income and Local Inequality on Self-Identification as a `Have-Not'}
  \label{F:t3_multi}
  \begin{center}
    \includegraphics[width=5.9in]{figures/t3_multi.pdf}
  \end{center}
  \begin{footnotesize}
  \begin{tabular}{p{.1in} p{6.1in}}
  & \emph{Notes}: Dots and solid lines indicate estimates; whiskers and shaded regions represent 95\% confidence intervals.
Income is estimated to have a negative effect on identifying as a have-not that is strong, statistically significant, and larger in magnitude as local income inequality increases.
There is no support, however, for the conclusion reached in NJL that lower income people are more likely to identify as have-nots when they live in contexts of greater income inequality.
  \end{tabular}
  \end{footnotesize}
\end{figure}
\end{spacing}


<<label=additional_analyses>>==
# Cross-classified model with level for survey makes no difference
# t2_all2 <- with(hhn_mi, 
#                glmer(formula = div_hhn~gini_cnty+
#                          income_cnty+black_cnty+perc_bush04+pop_cnty+
#                          income+educ+age+male+union+emp+partyid+ideo+attend+
#                          (1|fips) + (1|survey), family=binomial(link="logit")))
# t2_all2_res <- format_mi_results(t2_all2)
# summary(t2_all2_res)
# beep()

# No sign of interaction either: gini_cnty not significant at any income
# t2_all3 <- with(hhn_mi, 
#                 glmer(formula = div_hhn~gini_cnty+
#                           income_cnty+black_cnty+perc_bush04+pop_cnty+
#                           income+educ+age+male+union+emp+partyid+ideo+attend+gini_cnty:income +
#                           (1|fips) + (1|survey), family=binomial(link="logit")))
# t2_all3_res <- format_mi_results(t2_all3)
# summary(t2_all3_res)
# interplot(t2_all3, "gini_cnty", "income")
# beep()
@

\clearpage
\pagebreak
\newpage
\bibliographystyle{ajps}
\bibliography{FSLibrary}

\end{document}
