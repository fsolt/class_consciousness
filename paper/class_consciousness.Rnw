\documentclass[12pt]{article}
%\usepackage{fullpage}

\usepackage{graphicx}        % Enable graphics commands
\usepackage{lscape}		% Enable landscape with \begin{landscape} until \end{landscape}
\usepackage{natbib}			% Enable citation commands \citep{}, \citet{}, etc.
\bibpunct{(}{)}{;}{a}{}{,}		% Formatting for in-text citations
\usepackage{setspace}		% Enable double-spacing with \begin{spacing}{2} until \end{spacing}.
\usepackage[utf8]{inputenc} 	% Enable utf8 characters, i.e., accents without coding--just type them in.
\usepackage[english]{babel}	% English hyphenation and alphabetization.  Other languages available.
\usepackage{dcolumn}        % For decimal-aligned stargazer/texreg output.
\usepackage[colorlinks=true, urlcolor=blue, citecolor=black, linkcolor=black]{hyperref} % Include hyperlinks with the \url and \href commands.
\setlength{\tabcolsep}{1pt}	% Make tables slightly narrower by reducing space between columns.
\usepackage{afterpage}
\usepackage{hanging}
\usepackage[margin=1in]{geometry}

\usepackage{ntheorem}
\newtheorem{hyp}{Hypothesis} 

\renewcommand\floatpagefraction{.9}	% These commands allow larger tables and graphics to fit
\renewcommand\topfraction{.9}		% on a page when default settings would complain.
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\newcommand{\R}{\textsf{R}~}        %This creates the command \R to typeset the name R correctly.
\mathchardef\mhyphen="2D            %Math-mode hyphen

%\usepackage[left=1in, right=1in]{geometry}	
%Turn footnotes into endnotes (commented out).
%\renewcommand{\footnotesize}{\normalsize}	
% \usepackage{endnotes}
% \renewcommand{\footnote}{\endnote}
\renewcommand{\section}{\subsubsection}

\begin{document}

<<include=FALSE>>=
library(knitr)
opts_chunk$set(concordance=TRUE, cache=TRUE, warning=FALSE, message=FALSE, echo=FALSE, results='hide')
@

\title{Economic Inequality and\\ Class Consciousness in the United States\thanks{Revision history and the materials needed to reproduce the analyses of this paper can be found \href{https://github.com/fsolt/class_consciousness}{on Github here}.}}
\author{
  Frederick Solt\\
  \href{mailto:frederick-solt@uiowa.edu}{frederick-solt@uiowa.edu}
  \and
  Yue Hu\\
  \href{mailto:yue-hu-1@uiowa.edu}{yue-hu-1@uiowa.edu}
    \and
	Kevan Hudson\\
	\href{mailto:kevan-hudson@uiowa.edu}{kevan-hudson@uiowa.edu}
	\and
	Jungmin Song\\
    \href{mailto:jungmin-song@uiowa.edu}{jungmin-song@uiowa.edu}
	\and
	Dong `Erico' Yu\\
    \href{mailto:dong-yu@uiowa.edu}{dong-yu@uiowa.edu}
}
\date{\today}				
\maketitle

\begin{spacing}{2}
\begin{abstract}

\end{abstract}

\newpage


<<label=setup>>==
library(readr)
library(haven)
library(ggplot2)
library(dplyr)
library(magrittr)
library(stringr)
library(lme4)
library(mi)
library(betareg)
library(truncnorm)
library(mitools)
library(beepr)
library(dotwhisker)
@


<<label=format_fxns>>==
gen_partyid <- function(df) {
	pid <- rep(NA, length(df$party))
	pid[df$party==1 & df$partystr==1] <- 5
	pid[df$party==1 & df$partystr==2] <- 4
	pid[df$partyln==1] <- 4
	pid[(df$party==3 | df$party==4) & df$partyln==9] <- 3
	pid[df$partyln==2] <- 2
	pid[df$party==2 & df$partystr==2] <- 2
	pid[df$party==2 & df$partystr==1] <- 1
	return(pid)
}

gen_partyid2 <- function(df) {
	pid <- rep(NA, length(df$party))
	pid[df$party==1 & df$partystr==1] <- 7
	pid[df$party==1 & df$partystr==2] <- 6
	pid[df$partyln==1] <- 5
	pid[(df$party==3 | df$party==4) & df$partyln==9] <- 4
	pid[df$partyln==2] <- 3
	pid[df$party==2 & df$partystr==2] <- 2
	pid[df$party==2 & df$partystr==1] <- 1
	return(pid)
}

hhn_format <- function(df, cfips, dh, hn) {
	# clean a Pew have/have-not survey dataset and merge it with county-level data
	# df: data; cfips: var of county fips; dh: var of U.S. divided; hn: var of self-id as have-not
    surv <- str_replace(deparse(substitute(df)), "hhn", "20")
    all_vars <- c("income", "educ", "age", "sex", "racethn", "race", "hisp", 
                  "labor", "ideo", "attend", "employ",
    			  "party", "partystr", "partyln")
    vars <- c(cfips, dh, hn, all_vars[all_vars %in% names(df)])
    df %<>% select(one_of(vars))
    names(df)[1:3] <- c("cfips", "dh", "hn")
    df %<>% mutate(
        fips = as.integer(cfips),
        state = floor(fips/1000),
        div_hhn = ifelse(dh==1, 1, ifelse(dh==2, 0, NA)),
        have_not = ifelse(hn==2, 1, ifelse(hn==1, 0, NA)),
        income = as.integer(ifelse(income<=9, income, NA)), # 1 to 9
        educ = as.integer(ifelse(educ<=7, educ, NA)), # 1 to 7
        age = ifelse(age<99, age, NA),
        male = ifelse(sex==1, 1, 0),
        ideo = as.integer(6 - ifelse(ideo<=5, ideo, NA)) # 1 to 5
    )
    df$partyid <- gen_partyid(df)
    if (names(df) %>% str_detect("racethn") %>% any()) {
        df %<>% mutate(white = ifelse(racethn==1, 1, 0))
    } else df %<>% mutate(white = ifelse(race==1 & hisp!=1, 1, 0))
    if (names(df) %>% str_detect("labor") %>% any()) {
        df %<>% mutate(union = ifelse(labor<=3, 1, ifelse(labor==4, 0, NA)))
    } else df %<>% mutate(union = NA)
    if (names(df) %>% str_detect("attend") %>% any()) {
        df %<>% mutate(attend = 7 - ifelse(attend<=6, attend, NA))
    } else df %<>% mutate(attend = NA)
    if (names(df) %>% str_detect("employ") %>% any()) {
        df %<>% mutate(emp = ifelse(employ<3, 1, ifelse(employ==3, 0, NA)))
    } else df %<>% mutate(emp = NA)

    df$survey <- surv
    
    vars2 <- c("fips", "state", "div_hhn", "have_not", "income", "educ", "age", "male", "white", 
               "union", "emp", "partyid", "ideo", "attend", "survey")
    df %<>% select(one_of(vars2)) %>% left_join(cnty_data, by = "fips") %>% filter(white==1)
} 

hhn_mi <- function(df, seed=324) {
	# multiply impute missing data in a cleaned and merged Pew dataset
    mdf <- missing_data.frame(as.data.frame(df))
    mdf <- change(mdf, y = c("fips", "state"), what = "type", to = "irrelevant")
    mdf <- change(mdf, y = c("income", "educ", "attend"), what = "type", to = "ordered-categorical")
    mdf <- change(mdf, y = "age", what = "type", to = "bounded-continuous", lower=18, upper=97)
    mdf_mi <- mi(mdf, seed=seed) 
    
    # switch to mitools format (no support for glmer in mi::pool)
    mdf_mi_list <- complete(mdf_mi, m=10) 
    mdf_mi_list <- lapply(mdf_mi_list, function(df) 
        sapply(df, function(v) 
            if(any(class(v)=="factor")) v <- as.numeric(levels(v))[v] else v <- v) %>% data.frame) # get rid of %&*(&^ factors
    imputationList(mdf_mi_list)
}

format_mi_results <- function(m) {
	# format results of analysis of multiply imputed Pew dataset
    m_fe <- MIextract(m, fun=fixef) # see https://books.google.com/books?id=EbLrQrBGid8C&pg=PA384
    m_vars <- MIextract(m, fun=vcov)
    m_vars2 <- list()
    m_vars2 <- lapply(m_vars, as.matrix)
    m_res <- MIcombine(m_fe, m_vars2)
    b <- m_res$coefficients
    se <- diag(m_res$variance^.5)
    df <- data.frame(term = names(b),
               estimate = b,
               std.error = se,
               model = deparse(substitute(m)), 
               stringsAsFactors = FALSE)
    df %>% filter(term!="(Intercept)")
}
@

<<label=county_data>>==
## Replicate county-level data from sources
fips_cnty <- read_csv("https://raw.githubusercontent.com/raypereda/fips-county-codes/master/lib/national.txt", 
					  col_types="ccccc") 
names(fips_cnty) <- tolower(gsub(" ", "_", names(fips_cnty)))
fips_cnty$fips <- as.numeric(do.call(paste0, c(fips_cnty[, c(2,3)])))
fips_cnty$county <- tolower(gsub(" County| Parish", "", fips_cnty$county_name))
fips_cnty$county <- gsub(" ", "", fips_cnty$county)

bush04 <- read_tsv("http://bactra.org/election/vote-counts-with-NE-aggregated")
bush04$perc_bush04 <- with(bush04, Bush/(Bush+Kerry+Nader))
names(bush04) <- tolower(names(bush04))
bush04$county <- tolower(gsub(" County| Parish", "", bush04$county))
bush04$county <- gsub("saint", "st.", bush04$county)
bush04$county <- gsub(" ", "", bush04$county)
bush04$county[(bush04$state=="LA"|bush04$state=="MS") & bush04$county=="jeffdavis"] <- "jeffersondavis"
bush04$county[(bush04$state=="ME") & bush04$county=="linc"] <- "lincoln"
bush04$county[(bush04$state=="ME") & bush04$county=="andr"] <- "androscoggin"
bush04$county[(bush04$state=="ME") & bush04$county=="pen-s"] <- "penobscot"
bush04$county[(bush04$state=="ME") & bush04$county=="som-s"] <- "somerset"
bush04$county[(bush04$state=="ME") & bush04$county=="oxf-s"] <- "oxford"
bush04$county[(bush04$state=="MA") & bush04$county=="hamd"] <- "hamden"
bush04$county[(bush04$state=="MA") & bush04$county=="esse"] <- "essex"
bush04$county[(bush04$state=="MA") & bush04$county=="hams"] <- "hampshire"
bush04$county[(bush04$state=="NH") & bush04$county=="graf"] <- "grafton"
bush04$county[(bush04$state=="NY") & bush04$county=="manhattan"] <- "newyork"
bush04$county[(bush04$state=="NY") & bush04$county=="statenisland"] <- "richmond"
bush04$county[(bush04$state=="NY") & bush04$county=="brooklyn"] <- "kings"
bush04$county[(bush04$state=="VT") & bush04$county=="fran"] <- "franklin"
bush04$county[(bush04$state=="VT") & bush04$county=="wins"] <- "windsor"
bush04$county[(bush04$state=="VT") & bush04$county=="addi"] <- "addison"
bush04$county[(bush04$state=="VT") & bush04$county=="gris"] <- "grandisle"
bush04$county[(bush04$state=="VT") & bush04$county=="oran"] <- "orange"
bush04$county[(bush04$state=="VA") & bush04$county=="manassas"] <- "manassascity"
bush04$county[(bush04$state=="VA") & bush04$county=="norton"] <- "nortoncity"

bush04_cnty <- left_join(bush04, fips_cnty)
missing <- bush04_cnty[is.na(bush04_cnty$fips), 1:8] # election results still without fips due to county name inconsistencies
bush04_cnty <- bush04_cnty[!is.na(bush04_cnty$fips), ] # keep only results that already have fips
remaining <- anti_join(fips_cnty, bush04) %>% arrange(state) # fips without election results

missing$county0 <- missing$county # move county names to a tempvar
missing$county <- NA

states <- unique(missing$state)
states <- states[states != "AK"] # nothing to be done with Alaska election results--no breakdown in data
for(i in 1:length(states)) {
	t.rem <- remaining$county[remaining$state==states[i]] # fips without election results, one state at a time
	missing$county[missing$state==states[i]] <- lapply(missing$county0[missing$state==states[i]], function (ii) agrep(ii, t.rem, value=T, max.distance=.2)) # find matches to county name by state
}
missing$county <- unlist(lapply(missing$county, function(ii) ii[1])) # use closest match to county name
missing <- left_join(missing, fips_cnty) # now merge; some results still without fips in Maine, otherwise good
missing$county0 <- NULL # drop tempvar

bush04_cnty %<>% rbind(missing) %>% select(fips, perc_bush04)

acs0509 <- read_csv("../data/acs0509-counties.csv") # this throws warnings; they are irrelevant
names(acs0509) <- tolower(names(acs0509))
acs0509 <- mutate(acs0509,
				  fips = as.numeric(gsub("05000US", "", geoid)),
				  gini_cnty = b19083_001e,
				  income_cnty = b19013_001e/10000,
				  black_cnty = b02001_003e/b02001_001e,
				  pop_cnty = b02001_001e/10000)
cnty_data <- select(acs0509, fips:pop_cnty) %>% left_join(bush04_cnty)
@

<<label=repro>>==
vars_list <- c("gini_cnty", "income_cnty", "black_cnty", "perc_bush04", "pop_cnty", "income",
              "educ", "age", "male", "union", "emp", "partyid", "ideo", "attend", "(Intercept)")
vars_proper <- c("Gini Index", "Median Household Income", "Percent Black", "Bush Vote", 
                "Total Population", "Income", "Education", "Age", "Male", "Union Membership",
                "Employed", "Republican Party ID", "Conservative Ideology",
                "Religious Attendance")

### 2006 (Table 2)
hhn06 <- read_dta("../data/pew/haves_havenots/Sept06/Sept06NIIc.dta") # Converted first with StatTransfer as read_sav didn't work
hhn06x <- hhn_format(hhn06, cfips="fips", dh="q52", hn="q53")

hhn06x_mi <- hhn_mi(hhn06x) # multiply impute missing data

t2 <- with(hhn06x_mi, 
              glmer(formula = div_hhn~gini_cnty+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        income+educ+age+male+union+emp+partyid+ideo+attend+
                        (1|fips), family=binomial(link="logit")))
t2_res <- format_mi_results(t2)
#dwplot(t2_res)
@

<<label=replication_all>>==
### additional data
# load all datasets
hhn05 <- read_sav("../data/pew/haves_havenots/Oct05NII/Oct05NIIc.sav") # Oct05NII (all controls)
hhn06 <- read_dta("../data/pew/haves_havenots/Sept06/Sept06NIIc.dta") # used in Table 2
hhn07 <- read_sav("../data/pew/haves_havenots/July07/July07c.sav") # July07 (missing labor, employ)
hhn0801 <- read_dta("../data/pew/haves_havenots/Jan08/Jan08c.dta") # Jan08 (all controls)
hhn0810 <- read_sav("../data/pew/haves_havenots/EarlyOct08/EarlyOct08c.sav") # EarlyOct2008 (missing labor, attend)
hhn09 <- read_sav("../data/pew/haves_havenots/Values09/Values09c.sav") %>% # Values09 (all controls, but only Survey B asked hhn)
    filter(values==2) # keep only Survey B, which asked hhn questions

# no fips in Apr10-political-future;
#               Sept 22-25 2011 omnibus public; or 
#               Dec11 Political (they're too late for the acs0509 contextual data anyway)

# format all datasets
hhn05x <- hhn_format(hhn05, cfips="qfips", dh="q52", hn="q53")
hhn06x <- hhn_format(hhn06, cfips="fips", dh="q52", hn="q53")
hhn07x <- hhn_format(hhn07, cfips="qfips", dh="q40", hn="q41")
hhn0801x <- hhn_format(hhn0801, cfips="fips", dh="q33", hn="q34")
hhn0810x <- hhn_format(hhn0810, cfips="zfips", dh="q56", hn="q57")
hhn09x <- hhn_format(hhn09, cfips="fips", dh="qb28", hn="qb29")

# combine data
hhn <- rbind(hhn05x, hhn06x, hhn07x, hhn0801x, hhn0810x, hhn09x)
rm(list = ls(pattern="hhn0[5789].*")) # free up memory

hhn_mi <- hhn_mi(hhn)

t2_all <- with(hhn_mi, 
              glmer(formula = div_hhn~gini_cnty+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        income+educ+age+male+union+emp+partyid+ideo+attend+
                        (1|fips), family=binomial(link="logit")))
t2_all_res <- format_mi_results(t2_all)

level_brackets <- list(c("County-Level", "gini_cnty", "pop_cnty"),
                       c("Individual-Level", "income", "attend"))

p <- t2_res %>% by_2sd(hhn06x) %>%
    rbind(t2_all_res %>% by_2sd(hhn)) %>% dwplot +
    relabel_y_axis(vars_proper) +
    theme_bw() + xlab("Coefficient Estimate") +
    geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
    theme(legend.justification=c(0, 1), legend.position=c(0, 1),
          legend.background = element_rect(colour="grey80"),
          legend.title.align = .5) +
    scale_colour_grey(start = .5, end = .7,
                      name = "Dataset",
                      breaks = c("t2", "t2_all"),
                      labels = c("Pew 2006", "Pew 2005-2009"))
g <- p %>% add_brackets(level_brackets)
ggsave("figures/t2_pooled.pdf", plot = g, width = 6, height = 5)  
@

<<label=replication_each>>==
# Does any other single dataset yield same result as 2006? no
yrs <- c(2005, 2007, 200801, 200810, 2009)

for (i in 1:length(yrs)) {
    ds <- lapply(hhn_mi$imputations, function(x) x[x$survey==yrs[i],, drop=F]) %>% imputationList()
    res <- with(ds, 
              glmer(formula = div_hhn~gini_cnty+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        income+educ+age+male+union+emp+partyid+ideo+attend+
                        (1|fips), family=binomial(link="logit")))
    tidy_res <- format_mi_results(res)
    tidy_res$model <- paste("Pew", yrs[i])
    if (i==1) t2_by_survey <- tidy_res else t2_by_survey <- rbind(t2_by_survey, tidy_res)
}
@

<<label = replication_each_plot>>==
t2_by_survey %<>% rbind(t2_res %>% mutate(model = "Pew 2006")) %>% 
	arrange(model) # use 2006 data mi'd separately for consistency w first plot

sw <- secret_weapon(t2_by_survey, "gini_cnty") +
    theme_bw() + xlab("Coefficient Estimate, County Gini Index") + ylab("") + 
    relabel_y_axis(c("Oct 2005", "Sept 2006", "July 2007", 
                                            "Jan 2008", "Oct 2008", "Apr 2009")) +
    geom_vline(xintercept = 0, colour = "grey60", linetype = 2) + 
    theme(legend.position = "none")
ggsave("figures/t2_by_survey.pdf", plot = sw, width = 6, height = 3)
@


<<label = t3_replication>>==

t3_all <- with(hhn_mi, 
              glmer(formula = have_not~gini_cnty+income+gini_cnty:income+
                        income_cnty+black_cnty+perc_bush04+pop_cnty+
                        educ+age+male+union+emp+partyid+ideo+attend+
                        (1+income|fips), family=binomial(link="logit")))
t3_all_res <- format_mi_results(t3_all)

# Table 3 isn't reproducible as presented: it has more parameters than observations
# so we have to enter the reported results by hand
t3_rep <- data_frame(term = t3_all_res$term,
               estimate = c(2.27, -1.76, .625, -.082, 1.95, 1.09, -.679, -1.76, .156, .274,
                            .358, -1.49, -.538, -.058, -4.59),
               std.error = c(1.50, 1.05, .677, .632, .661, .835, .361, 1.05, .170, .235,
                             .205, .274, .401, .273, 2.62),
               model = "t3")

t3_adj <- hhn06x %>% 
  summarize_each(funs(min(., na.rm=TRUE), max(., na.rm=TRUE)))
t3_adj <- tidyr::gather(t3_adj, key = term, value = val)

t3_adj_max <- t3_adj %>% 
  filter(str_detect(term, "_max")) %>% 
  transmute(term = str_replace(term, "_max", ""),
            max = val) 

t3_adj_min <- t3_adj %>% 
  filter(str_detect(term, "_min")) %>% 
  transmute(term = str_replace(term, "_min", ""),
            min = val)

t3_rep %<>% left_join(t3_adj_max, by = "term") %>% left_join(t3_adj_min, by = "term")

#make adjustment


level_brackets <- list(c("County-Level Controls", "income_cnty", "pop_cnty"),
                       c("Individual-Level Controls", "educ", "attend"))

p3 <-  t3_rep %>% 
  rbind(t3_all_res %>% by_2sd(hhn)) %>% 
  dwplot() +
    relabel_y_axis(vars_proper) +
    theme_bw() + xlab("Coefficient Estimate") +
    geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
    theme(legend.justification=c(0, 1), legend.position=c(0, 1),
          legend.background = element_rect(colour="grey80"),
          legend.title.align = .5) +
    scale_colour_grey(start = .5, end = .7,
                      name = "Dataset",
                      breaks = c("t3", "t3_all"),
                      labels = c("Pew 2006, Reported", "Pew 2005-2009"))

g3 <- p3 %>% add_brackets(level_brackets)
ggsave("figures/t3_pooled.pdf", plot = g, width = 6, height = 5)
@


examine as much relevant evidence as possible

discuss Figure \ref{F:t2_pooled}

discuss Figure \ref{F:t2_by_survey}

An important step in the process of conducting sound research is striving to utilize all available data. Researchers should seek to conduct their analysis on the entirety of data that they have at their disposal. Doing so provides a number of benefits:  it increases the likelihood that the sample utilized captures the true distribution of the underlying population, and it affords greater leverage in testing the implications of one’s hypothesis. While the issue of selection bias cannot be avoided simply by including all available data, limiting analysis to a particular dataset, particularly when alternatives are available, may cast doubt on the inferences drawn from that analysis. By including all relevant data researchers are better able to observe the implications of their theory, thus providing greater support for the hypotheses they advance.

If research is limited to a particular source of data, the findings may be called into question. The limited data may provide evidence of a relationship that is not present in a larger, more representative sample. We can draw an example of the dangers of not including all relevant data from \citet{Newman2015}.  In an attempt to test some underlying assumptions of their theory the authors rely on 2006 Pew Research Center dataset due to its ``unique set of questions tapping perceptions of economic hierarchy and inequality and respondents perception of their own position within such a hierarchy'' \citep[336]{Newman2015}. As presented by the authors, this dataset provides the only source of information on responses to the question whether or not an American thinks of America as being divided into haves and have-nots, and whether they think of themselves as being haves or have-nots. Employing this dataset the authors find further support for their theory, in situations of higher inequality respondents are more likely to believe that America is divided in such a way, and the poor are more likely to identify themselves as have-nots. In reality, these questions are not unique to the 2006 dataset, but are instead present in each of the surveys the authors used in their earlier analysis. Perhaps it is by coincidence that, as shown in Figure \ref{F:t2_by_survey}, the coefficient of interest only achieves statistical significance when using the 2006 data. As illustrated, no other dataset produces a statistically significant coefficient for Gini according to the authors’ model. This provides a clear illustration of the importance of including all relevant data; failure to do so can lead to biased results.

The authors’ use of this severely truncated data has implications beyond the coefficient of interest as well. While Figure (INSERT FIGURE NUMBER) clearly demonstrates that a more careful inclusion of all data produce results that run counter to the findings of Newman et al, including all available data drastically changes the entre model, not merely the coefficient for Gini. Figure \ref{F:t2_pooled} provides estimates of the coefficients from Newman et al’s Table 2 (p. 336) with a sample that includes data from the 2005, 2006, 2007, and 2009 surveys they use earlier in their article. When all relevant data is included, the results are drastically different. Not only does the primary variable of interest (Gini coefficient) lose statistical significance, but others do as well. Having voted for Bush is no longer a statistically significant predictor of believing America is divided into the haves and have-nots, but income becomes strongly negative and significantly associated with the same belief. Additionally, union membership gains statistical significance, indicating that belonging to a union increases the likelihood an individual perceives that have/have-not division. Ultimately, Figure (INSERT NUMBER) provides graphical representation of the dangers of not including all available data. By limiting their analysis to the sole dataset that produced a statistically significant coefficient for inequality, the authors have disguised the true relationship in order to support their theory. A properly crafted analysis reveals findings that are far less surprising; the wealthy are less likely to see America as divided into the haves and have-nots, while union members are more likely to do so. These findings counter the primary argument advanced by Newman et al, and lend strong evidence to the claim that ``we should be willing to take whatever information we can acquire so long as it helps us learn about the veracity of our theory,'' while illustrating the pitfall of picking and choosing data that confirm our theory, while ignoring data that does not \citep[31]{King1994}.


\begin{figure}[htbp] 
  \caption{Local Inequality and the Perception of America as Divided into `Haves' and `Have-Nots': Results Using All Available Data}
  \label{F:t2_pooled}
  \begin{center}
    \includegraphics[width=5.25in]{figures/t2_pooled.pdf}
  \end{center}
  \begin{footnotesize}
  \begin{tabular}{p{.1in} p{5.1in}}
  & \emph{Notes}: Results from replications of the model presented in Table 2 of \citet{Newman2015} on the 2006 Pew survey analyzed in that article and on pooled data from the six Pew surveys that included the same item and were conducted in the time period the article examines.  The statistically significant result for county income inequality in the 2006 survey presented in that article is not evident when all of the available data are examined.
  \end{tabular}
  \end{footnotesize}
\end{figure}

\begin{figure}[htbp] 
  \caption{Local Inequality and the Perception of America as Divided into `Haves' and `Have-Nots': Results Using Each Available Dataset}
  \label{F:t2_by_survey}
  \begin{center}
    \includegraphics[width=5.25in]{figures/t2_by_survey.pdf}
  \end{center}
  \begin{footnotesize}
  \begin{tabular}{p{.1in} p{5.1in}}
  & \emph{Notes}: Results for county income inequality from replications of the model presented in Table 2 of \citet{Newman2015} on data from each of six available surveys conducted in the in the time period examined in that article.  Of the six surveys, the only one that yields a statistically significant result is the 2006 survey presented in the article.
  \end{tabular}
  \end{footnotesize}
\end{figure}

\end{spacing}


<<label = additional_analyses>>==
# Cross-classified model with level for survey makes no difference
# t2_all2 <- with(hhn_mi, 
#                glmer(formula = div_hhn~gini_cnty+
#                          income_cnty+black_cnty+perc_bush04+pop_cnty+
#                          income+educ+age+male+union+emp+partyid+ideo+attend+
#                          (1|fips) + (1|survey), family=binomial(link="logit")))
# t2_all2_res <- format_mi_results(t2_all2)
# summary(t2_all2_res)
# beep()

# No sign of interaction either: gini_cnty not significant at any income
# t2_all3 <- with(hhn_mi, 
#                 glmer(formula = div_hhn~gini_cnty+
#                           income_cnty+black_cnty+perc_bush04+pop_cnty+
#                           income+educ+age+male+union+emp+partyid+ideo+attend+gini_cnty:income +
#                           (1|fips) + (1|survey), family=binomial(link="logit")))
# t2_all3_res <- format_mi_results(t2_all3)
# summary(t2_all3_res)
# interplot(t2_all3, "gini_cnty", "income")
# beep()
@

\clearpage
\pagebreak
\newpage
\bibliographystyle{ajps}
\bibliography{FSLibrary}

\end{document}